/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: please do not edit it. Instead, edit the
// BAML files and re-generate this code using: baml-cli generate
// You can install baml-cli with:
//  $ npm install @boundaryml/baml
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code

const fileMap = {
  
  "voice_commands.baml": "// BAML schema for parsing voice commands\n// This provides type-safe LLM-powered command extraction\n\n// Define the command output structure\nclass VoiceCommand {\n  action string @description(\"The action to perform (e.g., CREATE_TIMER, RESET_TIMER, RANDOMISE)\")\n  target string @description(\"The widget target (e.g., timer, randomiser, list, poll)\")\n  confidence float @description(\"Confidence score from 0.0 to 1.0\")\n  parameters CommandParameters? @description(\"Optional parameters for the command\")\n  feedback FeedbackMessage? @description(\"Feedback message for the user (optional)\")\n}\n\nclass CommandParameters {\n  duration int? @description(\"Duration in seconds for timer commands\")\n  items string[]? @description(\"List of items for list widget\")\n  text string? @description(\"Text content for banner widget\")\n  soundName string? @description(\"Sound effect name\")\n  mode string? @description(\"Work mode for task cue\")\n  state string? @description(\"Traffic light state\")\n  options string[]? @description(\"Poll options\")\n}\n\nclass FeedbackMessage {\n  message string @description(\"Human-readable feedback message\")\n  type string @description(\"Message type: success or error\")\n  shouldSpeak bool? @description(\"Whether to use text-to-speech (defaults to true)\")\n}\n\n// Main function for parsing voice commands\nfunction ParseVoiceCommand(transcript: string) -> VoiceCommand {\n  client OllamaClient\n\n  prompt #\"\n    You are a voice command parser for a classroom widget application.\n    Parse the following voice command: \"{{ transcript }}\"\n\n    Available actions: CREATE_TIMER, RESET_TIMER, PAUSE_TIMER, CREATE_LIST, CREATE_POLL, START_POLL,\n    CREATE_RANDOMISER, RANDOMISE, CREATE_QUESTIONS, CREATE_TRAFFIC_LIGHT, CREATE_TEXT_BANNER, UNKNOWN\n\n    Available widgets: timer, randomiser, list, poll, questions, trafficLight, textBanner, soundEffects\n\n    CRITICAL: Return ONLY the raw JSON object. Do not wrap it in markdown code blocks. Do not include ```json or ```. Just return the pure JSON.\n\n    Example of correct output:\n    {\"action\": \"CREATE_TIMER\", \"target\": \"timer\", \"confidence\": 0.9, \"parameters\": {\"duration\": 300}, \"feedback\": {\"message\": \"Creating a 5-minute timer\", \"type\": \"success\", \"shouldSpeak\": true}}\n\n    Return a JSON object with these exact fields:\n    - action: one of the available actions above\n    - target: one of the available widgets above\n    - confidence: a number between 0.0 and 1.0\n    - parameters: an object with optional fields (duration, items, text, etc.)\n    - feedback: an object with message (string), type (string: \"success\" or \"error\"), shouldSpeak (boolean)\n\n    Extract the action, target widget, parameters, and confidence (0.8-0.95 for clear commands).\n    Provide a helpful feedback message.\n  \"#\n}\n\n// Client configuration for Ollama\n// NOTE: Ollama provider uses OpenAI-compatible endpoints at /v1\nclient OllamaClient {\n  provider ollama\n  options {\n    model \"qwen2.5:0.5b\"\n    base_url \"http://localhost:11434/v1\"\n  }\n}\n",
}
export const getBamlFiles = () => {
    return fileMap;
}