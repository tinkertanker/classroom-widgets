# Server Configuration
PORT=3001
NODE_ENV=development

# Server Implementation Selection
# Set to 'true' to use the new modular server, 'false' for legacy monolithic server
# If not set, defaults to 'true' (new server) in all environments
# Set to 'false' to use the legacy monolithic server
USE_NEW_SERVER=true

# Admin Configuration
# Required for admin endpoints like /api/admin/cleanup
ADMIN_TOKEN=your-secret-admin-token

# CORS Configuration (optional)
# Comma-separated list of allowed origins
# CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# Logging Configuration
# Options: error, warn, info, debug
LOG_LEVEL=info

# Session Configuration
# Maximum participants per session
MAX_PARTICIPANTS_PER_SESSION=100

# Cleanup interval in milliseconds (default: 1 hour)
CLEANUP_INTERVAL=3600000

# Session timeout in milliseconds (default: 24 hours)
SESSION_TIMEOUT=86400000

# ============================================
# Voice Command LLM Service Configuration
# ============================================

# Set to 'true' to use local Ollama LLM instead of MockLLMService pattern matching
# Requires Ollama installation: https://ollama.com/
# See docs/LOCAL_LLM_SETUP.md for complete setup guide
USE_LOCAL_LLM=false

# Ollama Configuration (only used if USE_LOCAL_LLM=true)
# Model to use for voice command processing
# Recommended: phi4 (best accuracy), llama3.2:3b (good balance), gemma2:2b (faster)
OLLAMA_MODEL=phi4

# Ollama server URL (default: http://localhost:11434)
OLLAMA_HOST=http://localhost:11434